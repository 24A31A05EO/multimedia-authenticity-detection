# Multimedia Authenticity Detection System - Backend

A FastAPI backend for detecting fake/AI-generated images, videos, audio, phishing URLs, and AI-generated emails.

## ğŸš€ Quick Start

### 1. Prerequisites

- Python 3.11+
- pip or conda

### 2. Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configure Environment

```bash
# Copy example env file
cp .env.example .env

# Edit .env with your Supabase credentials
# SUPABASE_URL=https://your-project.supabase.co
# SUPABASE_KEY=your-service-role-key
```

### 4. Add ML Models (Optional)

Place your trained `.h5` models in the `models/` directory:

```
models/
â”œâ”€â”€ image_model.h5    # CNN for fake image detection
â”œâ”€â”€ video_model.h5    # CNN for deepfake detection
â”œâ”€â”€ audio_model.h5    # Spectrogram CNN for fake audio
â”œâ”€â”€ url_model.h5      # ML model for phishing URLs
â””â”€â”€ email_model.h5    # NLP model for AI-generated emails
```

> **Note:** The backend will work without models using heuristic fallback analysis.

### 5. Run the Server

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/detect/image` | Detect fake/AI-generated images |
| POST | `/api/detect/video` | Detect deepfake videos |
| POST | `/api/detect/audio` | Detect AI-generated audio |
| POST | `/api/detect/url` | Detect phishing URLs |
| POST | `/api/detect/email` | Detect AI-generated emails |
| GET | `/` | API information |
| GET | `/health` | Health check |

## ğŸ“¤ Request/Response Format

### File Upload (Image, Video, Audio)

```bash
curl -X POST "http://localhost:8000/api/detect/image" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@test_image.jpg"
```

### URL Detection

```bash
curl -X POST "http://localhost:8000/api/detect/url" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://suspicious-site.com/login"}'
```

### Email Detection

```bash
curl -X POST "http://localhost:8000/api/detect/email" \
  -H "Content-Type: application/json" \
  -d '{
    "subject": "Urgent: Verify your account",
    "body": "Click here to verify your account immediately...",
    "sender": "support@suspicious-domain.tk"
  }'
```

### Response Format

```json
{
  "result": "authentic | fake | suspicious",
  "confidence": 85.6,
  "details": "Explanation of the detection result"
}
```

## ğŸ—„ï¸ Supabase Setup

Create the `detections` table in Supabase:

```sql
CREATE TABLE detections (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  type TEXT NOT NULL,
  result TEXT NOT NULL,
  confidence FLOAT NOT NULL,
  details TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Enable RLS
ALTER TABLE detections ENABLE ROW LEVEL SECURITY;

-- Allow inserts (adjust as needed)
CREATE POLICY "Allow inserts" ON detections
  FOR INSERT WITH CHECK (true);
```

## ğŸ§  Model Training (Optional)

The backend expects TensorFlow/Keras `.h5` models. Example model architectures:

### Image Model (CNN)
- Input: 224x224x3 RGB image
- Output: Binary classification (authentic/fake)

### Video Model (Frame-based CNN)
- Input: 224x224x3 RGB frames
- Output: Binary classification per frame

### Audio Model (Spectrogram CNN)
- Input: 128x128 Mel spectrogram
- Output: Binary classification

### URL/Email Models
- Input: Feature vectors (see services for feature extraction)
- Output: Binary classification

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration settings
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ supabase.py      # Supabase client
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ image.py         # Image detection endpoint
â”‚   â”‚   â”œâ”€â”€ video.py         # Video detection endpoint
â”‚   â”‚   â”œâ”€â”€ audio.py         # Audio detection endpoint
â”‚   â”‚   â”œâ”€â”€ url.py           # URL detection endpoint
â”‚   â”‚   â””â”€â”€ email.py         # Email detection endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ image_service.py # Image analysis logic
â”‚   â”‚   â”œâ”€â”€ video_service.py # Video analysis logic
â”‚   â”‚   â”œâ”€â”€ audio_service.py # Audio analysis logic
â”‚   â”‚   â”œâ”€â”€ url_service.py   # URL analysis logic
â”‚   â”‚   â””â”€â”€ email_service.py # Email analysis logic
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ response.py      # Response models
â”œâ”€â”€ models/                   # ML model files (.h5)
â”œâ”€â”€ .env                      # Environment variables
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This file
```

## ğŸ”§ Frontend Integration

Update your frontend API configuration to point to:

```javascript
const API_BASE_URL = 'http://localhost:8000';
```

Example API call:

```typescript
const detectImage = async (file: File) => {
  const formData = new FormData();
  formData.append('file', file);
  
  const response = await fetch(`${API_BASE_URL}/api/detect/image`, {
    method: 'POST',
    body: formData,
  });
  
  return response.json();
};
```

## ğŸ“ License

MIT License
